Management Training Case

The HR department at Nextech, a large multinational manufacturer of computer- and mobile-related hardware, recently invested in a management training program for the company’s newly promoted managers. The program is designed to help high-performing individual contributors (ICs) transition into management roles more effectively. Such training is needed because the skills that make someone a successful IC, such as technical expertise and individual problem-solving, often differ from those required for effective management: leadership, communication, delegation, conflict resolution, and emotional intelligence. The head of HR at Nextech, Susan Lorenzo, noted in her proposal that “the program should enhance managers’ abilities to improve team dynamics and productivity, leading to better overall team performance.”

The training program was expensive to design and implement. In order to justify the expense—and mindful that research has not conclusively demonstrated “the effectiveness of current leadership development initiatives” (Lacerenza et. al., 2017)—Ms. Lorenzo insisted on evaluating the program with a randomized controlled trial before rolling it out to all the managers at Nextech.

Philip Mehta, a data scientist in the HR department, was asked to design and analyze the study. This should have been straightforward. Managers were randomly assigned to the training program. With proper randomization, estimating the average treatment effect of the program would be easy: engagement scores for employees whose managers did the training would be compared with those whose managers did not. Unfortunately, some managers assigned to the training did not attend, while others attended without having been assigned. This is called non-compliance.1 As a result, Philip’s nicely designed randomized study more closely resembled an observational one, with likely self-selection bias. The program probably appealed to more motivated managers who might have had relatively high engagement scores even without the training.

Philip thus needs to estimate the treatment effect of the training program despite possible confounders. To provide the management team at Nextech with a clear and easily interpretable assessment, he decides to use matching, a method that aims to mimic the simplicity and credibility of a randomized experiment. An additional reason for choosing matching: he knows that Ms. Lorenzo is a big proponent of using design-based rather than model-based causal inference with observational data.